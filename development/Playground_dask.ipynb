{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89d3092-646b-4083-8f2c-cc611d877ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83593/2270838566.py:5: FutureWarning: In version 2024.7.0 (target date: 2024-06-30 11:59:59-05:00), this will be an error.\n",
      "To raise these warnings as errors (and get stack traces to find out where they're called), run\n",
      "    import warnings\n",
      "    warnings.filterwarnings(\"error\", module=\"coffea.*\")\n",
      "after the first `import coffea` or use `@pytest.mark.filterwarnings(\"error:::coffea.*\")` in pytest.\n",
      "Issue: coffea.nanoevents.methods.vector will be removed and replaced with scikit-hep vector. Nanoevents schemas internal to coffea will be migrated. Otherwise please consider using that package!.\n",
      "  from coffea.nanoevents.methods import vector\n"
     ]
    }
   ],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, BaseSchema\n",
    "from coffea.analysis_tools import PackedSelection, Cutflow\n",
    "import hist\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import vector\n",
    "import awkward as ak\n",
    "import dask_awkward as dak\n",
    "import hist.dask as hda\n",
    "import numba\n",
    "import pandas as pd\n",
    "import dask\n",
    "import copy\n",
    "import vector\n",
    "from collections import namedtuple\n",
    "vector.register_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8647cb14-50da-4274-9741-7f0566a3596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events,report = NanoEventsFactory.from_root(\n",
    "    '../data/p8_ee_ZH_ecm240/events_082532938.root:events',\n",
    "    schemaclass=BaseSchema,\n",
    "    metadata={'dataset':'ZH'},\n",
    "    uproot_options={\"allow_read_errors_with_report\": True}\n",
    ").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946c9a16-3528-43c2-be37-41e2bcd75da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_props = pd.DataFrame({\n",
    "    'Zm':{'name':'Zm','title':'Z Candidate mass','xlabel':'$Z_{mass}$ [GeV]','ylabel':'Events','bins':100,'xmin':0,'xmax':250},\n",
    "    'Zm_zoom':{'name':'Zm_zoom','title':'Z Candidate mass','xlabel':'$Z_{mass}$ [GeV]','ylabel':'Events','bins':40,'xmin':80,'xmax':100},\n",
    "    'Recoilm':{'name':'Recoilm','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':100,'xmin':0,'xmax':200},\n",
    "    'Recoilm_zoom':{'name':'Recoilm_zoom','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':200,'xmin':80,'xmax':160},\n",
    "    'Recoilm_zoom1':{'name':'Recoilm_zoom1','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':100,'xmin':120,'xmax':140},\n",
    "    'Recoilm_zoom2':{'name':'Recoilm_zoom2','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':200,'xmin':120,'xmax':140},\n",
    "    'Recoilm_zoom3':{'name':'Recoilm_zoom3','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':400,'xmin':120,'xmax':140},\n",
    "    'Recoilm_zoom4':{'name':'Recoilm_zoom4','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':800,'xmin':120,'xmax':140},\n",
    "    'Recoilm_zoom5':{'name':'Recoilm_zoom5','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':2000,'xmin':120,'xmax':140},\n",
    "    'Recoilm_zoom6':{'name':'Recoilm_zoom6','title':'Leptonic Recoil mass','xlabel':'$Recoil_{mass}$ [GeV]','ylabel':'Events','bins':100,'xmin':130.3,'xmax':140}\n",
    "})\n",
    "def get_1Dhist(name, var, flatten=True):\n",
    "    '''\n",
    "    name: eg. Zm\n",
    "    var: eg. variable containing array of mass of Z\n",
    "    flatten: If to flatten var before fill; True by default\n",
    "    Returns a histogram\n",
    "    '''\n",
    "    props = plot_props[name]\n",
    "    if flatten : var = dak.ravel(var)\n",
    "    return hda.Hist.new.Reg(props.bins, props.xmin, props.xmax).Double().fill(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee067a4-5e8e-4e41-8347-5817203f8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(events,collection,attribute,*cut):\n",
    "    if len(cut) != 0:\n",
    "        return events[collection+'/'+collection+'.'+attribute][cut[0]]\n",
    "    return events[collection+'/'+collection+'.'+attribute]\n",
    "def get_all(events,Collection,*basecut):\n",
    "    prefix = '/'.join([Collection]*2)+'.'\n",
    "    list_of_attr = [field.replace(prefix,'') for field in events.fields if field.startswith(prefix)]\n",
    "    replace_list = ['.','[',']']\n",
    "    valid_attr = list_of_attr\n",
    "    for rep in replace_list:\n",
    "        valid_attr = [field.replace(rep, '_') for field in valid_attr ]\n",
    "    part = namedtuple('particle', valid_attr)\n",
    "    return part(*[get(events,Collection,attr,*basecut) for attr in list_of_attr])\n",
    "def get_reco(Reconstr_branch, needed_particle, events):\n",
    "    part = namedtuple('particle', list(Reconstr_branch._fields))\n",
    "    return part(*[getattr(Reconstr_branch,attr)[get(events,needed_particle,'index')] for attr in Reconstr_branch._fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5b336a-fb13-4a1a-9940-4fbe0e11d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutflow_transform(o):\n",
    "    '''\n",
    "    Transform the cutflow object into a computable format by dask\n",
    "    '''\n",
    "    res = o.result()\n",
    "    labels = res.labels\n",
    "    nevonecut = {l:n for l,n in zip(labels,res.nevonecut)}\n",
    "    nevcutflow = {l:n for l,n in zip(labels,res.nevcutflow)}\n",
    "    labels.remove('initial')\n",
    "    masksonecut = {l:n for l,n in zip(labels,res.masksonecut)}\n",
    "    maskscutflow = {l:n for l,n in zip(labels,res.maskscutflow)}\n",
    "    return {'nevonecut':nevonecut,'nevcutflow':nevcutflow,'masksonecut':masksonecut,'maskscutflow':maskscutflow}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfdfc3b-ed8f-4979-b4d0-017767a0b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of labels:  6\n",
      "length of nevs:  6\n",
      "length of masks:  5\n"
     ]
    }
   ],
   "source": [
    "#Create a Packed Selection object to get a cutflow later\n",
    "cut = PackedSelection()\n",
    "cut.add('No cut', dak.ones_like(dak.num(get(events,'ReconstructedParticles','energy'),axis=1),dtype=bool))\n",
    "\n",
    "# Filter out any event with no reconstructed particles and generate Reconstructed Particle Attributes\n",
    "#ak.mask preserves array length\n",
    "at_least_one_recon = dak.num(get(events,'ReconstructedParticles','energy'), axis=1) > 0\n",
    "good_events = dak.mask(events,at_least_one_recon)\n",
    "cut.add('At least one Reco Particle', at_least_one_recon)\n",
    "\n",
    "Reco = get_all(good_events,'ReconstructedParticles')\n",
    "Muons = get_reco(Reco,'Muon#0',good_events)\n",
    "\n",
    "# Create Array of Muon Lorentz Vector\n",
    "Muon = ak.zip({\"px\":Muons.momentum_x,\"py\":Muons.momentum_y,\"pz\":Muons.momentum_z,\"E\":Muons.energy,\"q\":Muons.charge,}, with_name=\"Momentum4D\")\n",
    "\n",
    "# Muon pt > 10\n",
    "Muon_pt_cut = dak.any(Muon.pt > 10.0, axis=1)\n",
    "Muon = dak.mask(Muon, Muon_pt_cut) #ak.mask to preserve number of events\n",
    "cut.add('Muon $p_T$ > 10 [GeV]',Muon_pt_cut)\n",
    "\n",
    "# Produce all the combinations of Muon Pairs possible within an event\n",
    "combs = dak.combinations(Muon,2)\n",
    "\n",
    "# Get dimuons\n",
    "mu1 , mu2 = dak.unzip(combs)\n",
    "di_muon = mu1 + mu2\n",
    "\n",
    "# Selection 0 : Only one Z candidate in an event\n",
    "di_muon = dak.mask(di_muon, dak.num(di_muon) == 1)\n",
    "cut.add('$N_Z$',dak.num(Muon) == 2 ) #Having one Z candidate is same as having exactly two muons in an even\n",
    "\n",
    "# Choose dimuon which is made up of two oppositely charged muons\n",
    "q_sum = mu1.q + mu2.q\n",
    "q_sum_array = dak.mask(q_sum, ak.num(q_sum) == 1)\n",
    "q_sum_mask = dak.all(q_sum_array == 0, axis=1)\n",
    "Z_cand = dak.mask(di_muon , q_sum_mask)\n",
    "cut.add('Opp charge muons',q_sum_mask)\n",
    "\n",
    "\n",
    "#Recoil Calculation\n",
    "ecm = 240.0 #GeV # com energy\n",
    "Recoil = ak.zip({\"px\":0.0-Z_cand.px,\"py\":0.0-Z_cand.py,\"pz\":0.0-Z_cand.pz,\"E\":ecm-Z_cand.E},with_name=\"Momentum4D\")\n",
    "\n",
    "# Selection 1 : Selection 0 + 80 < M_Z < 100\n",
    "zmassmask = (Z_cand.mass > 80) & (Z_cand.mass < 100)\n",
    "Z_cand_sel1 = Z_cand[zmassmask]\n",
    "Recoil_sel1 = Recoil[zmassmask]\n",
    "zmassmask = ak.fill_none(zmassmask,[False],axis=0) #Replace None values at axis 0 with [False]\n",
    "zmassmask = ak.flatten(zmassmask)\n",
    "cut.add('80 < $M_Z$ < 100',zmassmask)\n",
    "\n",
    "#Prepare cutflows\n",
    "sel0_list = ['No cut','At least one Reco Particle', 'Muon $p_T$ > 10 [GeV]', '$N_Z$', 'Opp charge muons' ]\n",
    "sel1_list = ['No cut','At least one Reco Particle', 'Muon $p_T$ > 10 [GeV]', '$N_Z$', 'Opp charge muons', '80 < $M_Z$ < 100']\n",
    "print('length of labels: ', len(cut.cutflow(*sel0_list).result().labels))\n",
    "print('length of nevs: ', len(cut.cutflow(*sel0_list).result().nevonecut))\n",
    "print('length of masks: ', len(cut.cutflow(*sel0_list).result().masksonecut))\n",
    "sel0 = cutflow_transform(cut.cutflow(*sel0_list))\n",
    "sel1 = cutflow_transform(cut.cutflow(*sel1_list))\n",
    "\n",
    "#Prepare output\n",
    "#Choose the required histograms and their assigned variables to fill\n",
    "names = ['Zm','Zm_zoom','Recoilm','Recoilm_zoom','Recoilm_zoom1','Recoilm_zoom2','Recoilm_zoom3','Recoilm_zoom4','Recoilm_zoom5','Recoilm_zoom6']\n",
    "vars_sel0 = ([Z_cand.mass]*2) + ([Recoil.mass]*8)\n",
    "vars_sel1 = ([Z_cand_sel1.mass]*2) + ([Recoil_sel1.mass]*8)\n",
    "Output = {\n",
    "    'histograms': {\n",
    "        'sel0':{name:get_1Dhist(name,var) for name,var in zip(names,vars_sel0)},\n",
    "        'sel1':{name:get_1Dhist(name,var) for name,var in zip(names,vars_sel1)}\n",
    "    },\n",
    "    'cutflow': { #cutflow objects\n",
    "        'sel0': sel0,\n",
    "        'sel1': sel1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01eef2e-328d-4991-ad20-75c43de3b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "Output = dask.compute(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cb3e5de-010b-43b7-a638-18da6f068377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<div style=\"display:flex; align-items:center;\">\n",
       "<div style=\"width:290px;\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"-10 -105 270 120\">\n",
       "<line x1=\"-5\" y1=\"0\" x2=\"255\" y2=\"0\" style=\"fill:none;stroke-width:2;stroke:currentColor\"/>\n",
       "<text text-anchor=\"middle\" x=\"0\" y=\"15\" style=\"fill:currentColor;\">\n",
       "80\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"15\" style=\"fill:currentColor;\">\n",
       "100\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"125.0\" y=\"15\" style=\"fill:currentColor;\">\n",
       "Axis 0\n",
       "</text>\n",
       "<polyline points=\"  0,0   0,-1.76 6.25,-1.76 6.25,-3.52 12.5,-3.52 12.5,-2.82 18.75,-2.82 18.75,-4.93  25,-4.93  25,-4.23 31.25,-4.23 31.25,-5.28 37.5,-5.28 37.5,-4.58 43.75,-4.58 43.75,-4.23  50,-4.23  50,-7.39 56.25,-7.39 56.25,-6.69 62.5,-6.69 62.5,-8.8 68.75,-8.8 68.75,-6.34  75,-6.34  75,-6.34 81.25,-6.34 81.25,-12.7 87.5,-12.7 87.5,-14.4 93.75,-14.4 93.75,-23.2 100,-23.2 100,-25.7 106.25,-25.7 106.25,-23.6 112.5,-23.6 112.5,-41.9 118.75,-41.9 118.75,-45.8 125,-45.8 125,-67.3 131.25,-67.3 131.25,-91.2 137.5,-91.2 137.5,-100 143.75,-100 143.75,-91.5 150,-91.5 150,-62.7 156.25,-62.7 156.25,-38.7 162.5,-38.7 162.5,-20.1 168.75,-20.1 168.75,-18.3 175,-18.3 175,-14.4 181.25,-14.4 181.25,-12.7 187.5,-12.7 187.5,-7.75 193.75,-7.75 193.75,-9.51 200,-9.51 200,-7.04 206.25,-7.04 206.25,-3.52 212.5,-3.52 212.5,-6.69 218.75,-6.69 218.75,-4.58 225,-4.58 225,-1.76 231.25,-1.76 231.25,-2.46 237.5,-2.46 237.5,-2.46 243.75,-2.46 243.75,-1.41 250,-1.41 250,0\" style=\"fill:none; stroke:currentColor;\"/>\n",
       "</svg>\n",
       "</div>\n",
       "<div style=\"flex=grow:1;\">\n",
       "Regular(40, 80, 100, label='Axis 0')<br/>\n",
       "<hr style=\"margin-top:.2em; margin-bottom:.2em;\"/>\n",
       "Double() Σ=2324.0 <em>(3036.0 with flow)</em>\n",
       "\n",
       "</div>\n",
       "</div>\n",
       "</html>"
      ],
      "text/plain": [
       "Hist(Regular(40, 80, 100, label='Axis 0'), storage=Double()) # Sum: 2324.0 (3036.0 with flow)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zm = Output[0]['histograms']['sel0']['Zm_zoom']\n",
    "zm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a695f5e-fbab-4149-bfc5-b3d2b202402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(input_d):\n",
    "    '''\n",
    "    Take the output of processor and change the cutflow dictionary into a cutflow object\n",
    "    '''\n",
    "    d = copy.deepcopy(input_d)\n",
    "    for dataset in input_d.keys():\n",
    "        for sel in input_d[dataset]['cutflow'].keys():\n",
    "            df = pd.DataFrame(input_d[dataset]['cutflow'][sel])\n",
    "            print(df)\n",
    "            labels = list(df.index)\n",
    "            d[dataset]['cutflow'][sel] = Cutflow(labels,list(df['nevonecut']),list(df['nevcutflow']),list(df['masksonecut']),list(df['maskscutflow']),delayed_mode=False)\n",
    "    return d\n",
    "def transform2(input_d):\n",
    "    '''\n",
    "    Take the output of processor and change the cutflow dictionary into a cutflow object\n",
    "    '''\n",
    "    d = copy.deepcopy(input_d)\n",
    "    for dataset in input_d.keys():\n",
    "        for sel in input_d[dataset]['cutflow'].keys():\n",
    "            c = input_d[dataset]['cutflow'][sel]\n",
    "            d[dataset]['cutflow'][sel] = Cutflow(\n",
    "                list(c['masksonecut'].keys()),\n",
    "                list(c['nevonecut'].values())[1:],\n",
    "                list(c['nevcutflow'].values())[1:],\n",
    "                list(c['masksonecut'].values()),\n",
    "                list(c['maskscutflow'].values()),\n",
    "                delayed_mode=False)\n",
    "    return d         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6abb7a97-febe-4742-bc04-597a292a9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = transform2({'zh':Output[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24431702-640e-4c0c-82c4-41dede79517e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "spans must have compatible lengths",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcutflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msel0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myieldhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coffea/analysis_tools.py:906\u001b[0m, in \u001b[0;36mCutflow.yieldhist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m     hcutflow \u001b[38;5;241m=\u001b[39m honecut\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    905\u001b[0m     hcutflow\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcutflow\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[0;32m--> 906\u001b[0m     \u001b[43mhonecut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nevonecut\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m     hcutflow\u001b[38;5;241m.\u001b[39mfill(numpy\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(labels), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m), weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nevcutflow)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/hist/basehist.py:252\u001b[0m, in \u001b[0;36mBaseHist.fill\u001b[0;34m(self, weight, sample, threads, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll axes must be accounted for in fill, you may have used a disallowed name in the axes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m data \u001b[38;5;241m=\u001b[39m (data_dict[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim))\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/boost_histogram/_internal/hist.py:504\u001b[0m, in \u001b[0;36mHistogram.fill\u001b[0;34m(self, weight, sample, threads, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m     threads \u001b[38;5;241m=\u001b[39m cpu_count()\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m threads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_ars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_ars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_ars\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hist\u001b[38;5;241m.\u001b[39m_storage_type \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    508\u001b[0m     _core\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mmean,\n\u001b[1;32m    509\u001b[0m     _core\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mweighted_mean,\n\u001b[1;32m    510\u001b[0m }:\n",
      "\u001b[0;31mValueError\u001b[0m: spans must have compatible lengths"
     ]
    }
   ],
   "source": [
    "a['zh']['cutflow']['sel0'].yieldhist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cd019-1ef9-4b50-93ce-c8e6048b7b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
